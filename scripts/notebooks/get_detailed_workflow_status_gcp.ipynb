{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f19be5-b9eb-4424-a13b-3fe53c8e0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import google.auth\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from google.auth.transport.requests import Request as GoogleAuthRequest\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12231a99-840b-421e-b795-a05622bf2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud = \"AZURE\" \n",
    "cloud = \"GOOGLE\"\n",
    "\n",
    "# for GOOGLE PROD workspace\n",
    "# workspace_name = \"Imputation_pipeline_testing\"\n",
    "# workspace_project = \"morgan-fieldeng\"\n",
    "\n",
    "# for GOOGLE DEV workspace\n",
    "workspace_name = \"tsps_gcp_scratch_space_mma\"\n",
    "workspace_project = \"general-dev-billing-account\"\n",
    "\n",
    "# for AZURE workspace\n",
    "workspace_id = \"a4d49543-65cb-43ec-a9c5-631e71fa77b9\" # new\n",
    "# workspace_id = \"c8a8a57d-f9aa-4a66-8a1a-b0af1b3c10c8\" # old: tsps_dev_bp_02_01_2024_v1/imputation-pipeline-testing-03-07-2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e8529-56fa-474e-9ce0-9240e6ba85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth login --update-adc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadbe32-0e62-476a-88d3-20402a2bd635",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = \"dev\"\n",
    "TEASPOONS_SA_EMAIL = f\"tsps-{ENV}@broad-dsde-{ENV}.iam.gserviceaccount.com\"\n",
    "\n",
    "def get_access_token():\n",
    "    \"\"\"Get access token.\"\"\"\n",
    "    credentials, _ = google.auth.default()\n",
    "    \n",
    "    credentials.refresh(GoogleAuthRequest())\n",
    "    \n",
    "    return credentials.token\n",
    "\n",
    "\n",
    "def get_workflows_url(cloud, workspace_id, workspace_project, workspace_name, token):\n",
    "    if cloud == \"AZURE\":\n",
    "        return get_cromwell_url_azure(workspace_id, token)\n",
    "    elif cloud == \"GOOGLE\":\n",
    "        return f\"https://rawls.dsde-{ENV}.broadinstitute.org/api/workspaces/{workspace_project}/{workspace_name}\"\n",
    "\n",
    "\n",
    "def get_cromwell_url_azure(workspace_id, token):\n",
    "    \"\"\"\"Get url for cromwell reader.\"\"\"\n",
    "    \n",
    "    uri = f\"https://leonardo.dsde-{ENV}.broadinstitute.org/api/apps/v2/{workspace_id}?includeDeleted=false\"\n",
    "    \n",
    "    headers = {\"Authorization\": \"Bearer \" + token,\n",
    "               \"accept\": \"application/json\"}\n",
    "    \n",
    "    response = requests.get(uri, headers=headers)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    if status_code != 200:\n",
    "        return response.text\n",
    "\n",
    "    \n",
    "    for entries in json.loads(response.text): \n",
    "        # pprint(entries)\n",
    "        if entries['appType'] == 'WORKFLOWS_APP' and entries['proxyUrls']['cromwell-reader'] is not None:\n",
    "            cromwell_url = entries['proxyUrls']['cromwell-reader']\n",
    "            break\n",
    "    \n",
    "    if cromwell_url is None: \n",
    "        print(\"Cromwell is missing in current workspace\")\n",
    "        return\n",
    "    else:\n",
    "        return cromwell_url\n",
    "\n",
    "\n",
    "def get_cromwell_workflow(cloud, workflows_url, submission_id, workflow_id, token):\n",
    "    if cloud == \"AZURE\":\n",
    "        uri = f\"{workflows_url}/api/workflows/v1/{workflow_id}/metadata?includeKey=attempt&includeKey=start&includeKey=end&includeKey=status&includeKey=backendStatus&includeKey=executionStatus&includeKey=subWorkflowId&includeKey=workflowName\"\n",
    "        return get_cromwell_workflow_azure(uri, token)\n",
    "    elif cloud == \"GOOGLE\":\n",
    "        uri = f\"{workflows_url}/submissions/{submission_id}/workflows/{workflow_id}?includeKey=attempt&includeKey=backendStatus&includeKey=status&includeKey=start&includeKey=end&includeKey=executionStatus&includeKey=shardIndex&includeKey=subWorkflowId&includeKey=workflowName&expandSubWorkflows=false\"\n",
    "        return get_cromwell_workflow_google(uri, token)\n",
    "\n",
    "\n",
    "def get_cromwell_workflow_azure(uri, token):\n",
    "    headers = {\"Authorization\": \"Bearer \" + token,\n",
    "               \"accept\": \"application/json\"}\n",
    "    \n",
    "    response = requests.get(uri, headers=headers)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    if status_code != 200:\n",
    "        print(\"error fetching cromwell workflow metadata\")\n",
    "        print(response.text)\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_cromwell_workflow_google(uri, token, attempt=1):\n",
    "    headers = {\"Authorization\": \"Bearer \" + token,\n",
    "               \"accept\": \"application/json\"}\n",
    "    \n",
    "    response = requests.get(uri, headers=headers)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    if status_code != 200:\n",
    "        if status_code == 404 and attempt <= 3:\n",
    "            attempt += 1\n",
    "            # sometimes we get a transient 404, we should retry twice\n",
    "            print(f\"retrying call after {attempt} sec, attempt {attempt}\")\n",
    "            time.sleep(attempt)\n",
    "            return get_cromwell_workflow_google(uri, token, attempt=attempt)\n",
    "        print(\"error fetching cromwell workflow metadata\")\n",
    "        print(response.text)\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def clean_task_name(task_name, workflow_name=\"ImputationBeagle\"):\n",
    "    return task_name.replace(workflow_name + \".\", \"\")\n",
    "\n",
    "def print_in_red_bold(text):\n",
    "    print('\\x1b[1;31m' + text + '\\x1b[0m')\n",
    "\n",
    "def print_in_grey(text):\n",
    "    print('\\x1b[0;37m' + text + '\\x1b[0m')\n",
    "\n",
    "def get_retries(task_info):\n",
    "    return [w['attempt'] for w in task_info if int(w['attempt']) > 1]\n",
    "\n",
    "def get_task_durations(task_info, successful_only=True):\n",
    "    if successful_only:\n",
    "        return [[w['start'], w['end']] for w in task_info if ('end' in w and w['executionStatus'] == 'Done')]\n",
    "    else:\n",
    "        return [[w['start'], w['end']] for w in task_info if 'end' in w]\n",
    "\n",
    "def display_task_statuses(cloud, workflows_url, submission_id, workflow_id, token):\n",
    "    response = get_cromwell_workflow(cloud, workflows_url, submission_id, workflow_id, token)\n",
    "\n",
    "    retries = {} # dict of \"taskname\": [list of attempt numbers]\n",
    "    durations = {} # dict of \"taskname\": [list of durations]\n",
    "    \n",
    "    # pprint(response)\n",
    "    \n",
    "    print(f\"status: {response['status']}\")\n",
    "\n",
    "    for task, info in response['calls'].items():\n",
    "        n_total = len(info)\n",
    "        n_failed = len([w for w in info if w['executionStatus'] == 'Failed'])\n",
    "        failure_msg = \"\" if n_failed == 0 else f\"- {n_failed} failures\"\n",
    "        n_succeeded = len([w for w in info if w['executionStatus'] == 'Done'])\n",
    "\n",
    "        task_name = clean_task_name(task)\n",
    "        \n",
    "        # log retries\n",
    "        task_retries = get_retries(info)\n",
    "        n_retries = len(task_retries)\n",
    "        if task_name in retries:\n",
    "            retries[task_name].extend(task_retries)\n",
    "        else:\n",
    "            retries[task_name] = task_retries\n",
    "        # retries[task_name] = n_retries if task_name not in retries else n_retries + retries[task_name]\n",
    "\n",
    "        # log durations\n",
    "        task_durations = get_task_durations(info)\n",
    "        if task_name in durations:\n",
    "            durations[task_name].extend(task_durations)\n",
    "        else:\n",
    "            durations[task_name] = task_durations\n",
    "\n",
    "        # subtract retries from total number of tasks to get effective expected total\n",
    "        line_to_print = f\"{clean_task_name(task)} : {n_succeeded}/{n_total-n_retries} complete tasks {failure_msg}\"\n",
    "        if failure_msg:\n",
    "            print_in_red_bold(line_to_print)\n",
    "        elif n_succeeded == n_total-n_retries:\n",
    "            print_in_grey(line_to_print)\n",
    "        else:\n",
    "            print(line_to_print)\n",
    "    \n",
    "        if (\"ScatterAt\" in task): # and ((n_failed > 0) or (n_succeeded < n_total))):\n",
    "            for w in info:\n",
    "                shard = w['shardIndex']\n",
    "                \n",
    "                if 'subWorkflowId' in w:\n",
    "                    subworkflow_id = w['subWorkflowId']\n",
    "                    \n",
    "                    subworkflow_response = get_cromwell_workflow(cloud, workflows_url, submission_id, subworkflow_id, token)\n",
    "                    \n",
    "                    subworkflow_status = subworkflow_response['status']\n",
    "                    shard_status_msg = f\"  Shard {shard} status: {subworkflow_status}\"\n",
    "\n",
    "                    for subtask, subinfo in subworkflow_response['calls'].items():\n",
    "                        subtask_name = clean_task_name(subtask)\n",
    "                        \n",
    "                        # log retries\n",
    "                        subtask_retries = get_retries(subinfo)\n",
    "                        if subtask_name in retries:\n",
    "                            retries[subtask_name].extend(subtask_retries)\n",
    "                        else:\n",
    "                            retries[subtask_name] = subtask_retries\n",
    "                        # n_retries = len(get_retries(subinfo))\n",
    "                        # retries[subtask_name] = n_retries if subtask_name not in retries else n_retries + retries[subtask_name]\n",
    "\n",
    "                        # log durations\n",
    "                        subtask_durations = get_task_durations(subinfo)\n",
    "                        if subtask_name in durations:\n",
    "                            durations[subtask_name].extend(subtask_durations)\n",
    "                        else:\n",
    "                            durations[subtask_name] = subtask_durations\n",
    "\n",
    "                    if subworkflow_status == \"Succeeded\":\n",
    "                        print_in_grey(shard_status_msg)\n",
    "                        \n",
    "                    else:\n",
    "                        print(shard_status_msg)\n",
    "                        for subtask, subinfo in subworkflow_response['calls'].items():\n",
    "\n",
    "                            n_total = len(subinfo)\n",
    "                            \n",
    "                            n_succeeded = len([w for w in subinfo if w['executionStatus'] == 'Done'])\n",
    "\n",
    "                            failed = []\n",
    "                            for w in subinfo:\n",
    "                                if w['executionStatus'] == 'Failed':\n",
    "                                    if 'backendStatus' in w:\n",
    "                                        failed += [f\"shard {w['shardIndex']} failed with status {w['backendStatus']}\"]\n",
    "                                    else:\n",
    "                                        failed += [f\"shard {w['shardIndex']} failed with unknown backendStatus\"]\n",
    "                            # failed = [f\"shard {w['shardIndex']} failed with status {w['backendStatus']}\" for w in subinfo if w['executionStatus'] == 'Failed']\n",
    "\n",
    "                            n_failed = len(failed)\n",
    "                            n_retries = len([w for w in subinfo if int(w['attempt']) > 1])\n",
    "                            if n_failed > 0:\n",
    "                                print_in_red_bold(f\"     {clean_task_name(subtask)} : {n_succeeded}/{n_total-n_retries} total shards succeeded, {n_failed} failed. error messages:\")\n",
    "                                for message in failed:\n",
    "                                    print_in_red_bold(f\"       {message}\")\n",
    "                            elif n_succeeded == n_total:\n",
    "                                print_in_grey(f\"     {clean_task_name(subtask)} : Succeeded\")\n",
    "                            else:\n",
    "                                print(f\"     {clean_task_name(subtask)} : In progress; {n_succeeded}/{n_total-n_retries} shards succeeded so far\")\n",
    "                \n",
    "                else: # no subWorkflowId \n",
    "                    print(f\"  Shard {shard} has no workflowId yet\")\n",
    "\n",
    "    return retries, durations\n",
    "\n",
    "def get_duration(timestamp_pair):\n",
    "    format_string = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "    return datetime.strptime(timestamp_pair[1], format_string) - datetime.strptime(timestamp_pair[0], format_string)\n",
    "\n",
    "def avg_td(timedeltas):\n",
    "    if len(timedeltas) > 0:\n",
    "        return sum(timedeltas, timedelta(0)) / len(timedeltas)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1fdb4-0eee-4858-a542-896221c076c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"running on {ENV} {cloud}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d885f0-435d-4409-a086-6119bf6cf2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflows_url = get_workflows_url(cloud, workspace_id, workspace_project, workspace_name, get_access_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d7b67-07b5-4328-a8fc-1e22c78a51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = get_access_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8c1a1-e6f3-43d5-9c48-6752c33531b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AZURE DEV\n",
    "\n",
    "# workflow_id = \"aac49125-c06d-4e0f-9012-14e85b3f5aa5\" # july 11 500 samples\n",
    "# workflow_id = \"93ac95f9-1edc-456c-b989-8578ef0355bd\" # july 12 1000 samples failed\n",
    "# workflow_id = \"f0f8ada6-08bc-4faf-b749-3e660fb2ea76\" # july 14 1000 samples\n",
    "# workflow_id = \"4e233132-173a-45f1-a8b4-751cea4914bb\"\n",
    "\n",
    "# submission_id = None\n",
    "\n",
    "# GOOGLE PROD\n",
    "\n",
    "# GOOGLE DEV\n",
    "# submission_id = \"c313cd58-eca1-4a22-8d95-0f1df44debca\" # 42 samples\n",
    "# workflow_id = \"8f7250e9-e6a0-4563-9922-33939740b152\"\n",
    "\n",
    "# submission_id = \"355548fd-71e9-45b3-b213-4e482e0dfedf\"\n",
    "# workflow_id = \"0d297916-5cda-4a32-ac5d-79ad35b23bbc\" # 500 samples\n",
    "# workflow_id = \"c80cbb40-30bc-408b-80ba-1f9c6cff873b\" # 1000 samples\n",
    "# workflow_id = \"b72cbf26-7454-4c37-a64c-df0d5ccbe022\" # 5000 samples\n",
    "\n",
    "submission_id = \"9ae58e2e-6559-4eef-a0c2-fedc4dd434bc\"\n",
    "workflow_id = \"523fdcc8-2410-463f-806f-a7a6387484db\"\n",
    "\n",
    "retries, durations = display_task_statuses(cloud, workflows_url, submission_id, workflow_id, get_access_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f876c01-fe82-4b7f-afd7-ee70cab49ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_retries = sum([len(rt) for rt in retries.values()])\n",
    "print(f\"Total retries executed: {n_retries}. Details:\\n\")\n",
    "for task, retry_list in retries.items():\n",
    "    print(f\"{task}: {len(retry_list)}\")\n",
    "# pprint(retries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa639e-16e8-4bcf-b56f-d1c179bb811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average completed task times (HH:MM:SS):\\n\")\n",
    "for task, duration_list in durations.items():\n",
    "    avg_duration = avg_td([get_duration(p) for p in duration_list])\n",
    "    if avg_duration and \"Scatter\" not in task:\n",
    "        print(f\"{str(avg_duration).split('.')[0]} (n={len(duration_list)}) -> {task}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755b7d6-40c5-459f-b7f8-865298bbb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break down retries further for a task\n",
    "task_name = 'CountVariantsInChunksBeagle'\n",
    "task_retries = retries[task_name]\n",
    "for attempt in range(2,5):\n",
    "    n_attempts = sum([1 for rt in task_retries if rt == attempt])\n",
    "    print(f\"{attempt} attempts: {n_attempts}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
