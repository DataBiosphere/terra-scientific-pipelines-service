{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to mimic the actions of what the TSPS service would be doing.  \n",
    "\n",
    "User and Control workspace creation are outside the scope of this notebook and will need to be created elsewhere (through the UI is probably the easiest.  For the most realistic scenario, you would want the user and control workspace to be created by different accounts and the control workspace account given writer access to the user workspace.\n",
    "\n",
    "1. copy file from user workspace to control workspace\n",
    "2. update control workspace WDS with new row containing a unique id and location of the copied file\n",
    "3. create method in cbas (currently hello world wdl) - note this should be done as part of control workspace creation but since that is being done outside of this notebook we still need to make sure the method we're running is consistent\n",
    "4. launch submission of newly created method using the copied file as input\n",
    "5. copy file from control workspace to user workspace\n",
    "6. update user workspace WDS with new row containing same unique id and location of the copied file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import csv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env API urls\n",
    "env = \"prod\"\n",
    "WSM_URL = f'https://workspace.dsde-{env}.broadinstitute.org'\n",
    "TSPS_URL = f'https://tsps.dsde-{env}.broadinstitute.org'\n",
    "ORCH_URL = f'https://firecloud-orchestration.dsde-{env}.broadinstitute.org/'\n",
    "LEONARDO_URL= f'https://leonardo.dsde-{env}.broadinstitute.org/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token(verbose=False):\n",
    "    \"\"\"Get access token for pet managed identity in Azure.\"\"\"\n",
    "    if verbose:\n",
    "        !az login --identity --allow-no-subscriptions\n",
    "    else:\n",
    "        !az login --identity --allow-no-subscriptions --output none\n",
    "    cli_token = !az account get-access-token | jq .accessToken\n",
    "\n",
    "    return cli_token[0].replace('\"', '')\n",
    "\n",
    "def get_headers(verb='GET', verbose=False):\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ' + get_access_token(verbose),\n",
    "        'accept': '*/*'\n",
    "    }\n",
    "    \n",
    "    if verb == 'POST':\n",
    "        headers['Content-Type'] = 'application/json'\n",
    "\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get headers once - refresh this as needed\n",
    "HEADERS_GET = get_headers('GET')\n",
    "HEADERS_POST = get_headers('POST')\n",
    "\n",
    "### workspace functions\n",
    "def get_workspace_id(ws_project, ws_name, orch_url=ORCH_URL, verbose=False):\n",
    "    uri = f'{orch_url}/api/workspaces/{ws_project}/{ws_name}'\n",
    "    \n",
    "    response = requests.get(uri, headers=HEADERS_GET)\n",
    "    \n",
    "    return response.json()['workspace']['workspaceId']\n",
    "\n",
    "def get_workspace_sc_resource_id(ws_id, wsm_url=WSM_URL, verbose=False):\n",
    "    uri = f'{wsm_url}/api/workspaces/v1/{ws_id}/resources?offset=0&limit=10&resource=AZURE_STORAGE_CONTAINER'\n",
    "    \n",
    "    response = requests.get(uri, headers=HEADERS_GET)\n",
    "    \n",
    "    sc_resource_id = None\n",
    "    for info_dict in response.json()['resources']:\n",
    "        if info_dict['metadata']['controlledResourceMetadata']['accessScope'] == 'SHARED_ACCESS':\n",
    "            sc_resource_id = info_dict['metadata']['resourceId']         \n",
    "    \n",
    "    return sc_resource_id\n",
    "\n",
    "\n",
    "### file functions\n",
    "def get_sas_token_for_blob(blob_name, \n",
    "                           ws_id, \n",
    "                           ws_sc_id, \n",
    "                           permissions='r', \n",
    "                           wsm_url=WSM_URL,\n",
    "                           verbose=False):\n",
    "    uri = f'{wsm_url}/api/workspaces/v1/{ws_id}/resources/controlled/azure/storageContainer/{ws_sc_id}/getSasToken?sasPermissions={permissions}&sasBlobName={blob_name}'\n",
    "    \n",
    "    response = requests.post(uri, headers=HEADERS_GET, data='')\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()['url']\n",
    "\n",
    "# leonardo functions\n",
    "def get_apps_for_workspace_id(workspace_id,\n",
    "                              leonardo_url=LEONARDO_URL,\n",
    "                              verbose=False):\n",
    "    uri = f'{leonardo_url}/api/apps/v2/{workspace_id}?includeDeleted=false'\n",
    "    response = requests.get(uri, headers=HEADERS_GET)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def get_app_for_workspace_id(workspace_id,\n",
    "                             app_name,\n",
    "                             leonardo_url=LEONARDO_URL,\n",
    "                             verbose=False):\n",
    "    uri = f'{leonardo_url}/api/apps/v2/{workspace_id}?includeDeleted=false'\n",
    "    response = requests.get(uri, headers=HEADERS_GET)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# wds functions\n",
    "def get_types(instance_id,\n",
    "              wds_url,\n",
    "              api_version=\"0.2\",\n",
    "              verbose=False):\n",
    "    uri = f'{wds_url}/{instance_id}/types/v{api_version}'\n",
    "    response = requests.get(uri, headers=HEADERS_GET)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()\n",
    "              \n",
    "def query_records_for_type(instance_id,\n",
    "                           type_name,\n",
    "                           wds_url,\n",
    "                           api_version=\"0.2\",\n",
    "                           offset=0,\n",
    "                           limit=100,\n",
    "                           sort=\"asc\",\n",
    "                           verbose=False):\n",
    "    uri = f'{wds_url}/{instance_id}/search/v{api_version}/{type_name}'\n",
    "    \n",
    "    \n",
    "    body = json.dumps({\n",
    "        'offset': offset,\n",
    "        'limit': limit,\n",
    "        'sort': sort\n",
    "    })\n",
    "    \n",
    "    response = requests.post(uri, headers=HEADERS_POST, data=body)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def upload_records_for_type(instance_id,\n",
    "                            type_name,\n",
    "                            wds_url,\n",
    "                            tsv_file_path,\n",
    "                            api_version=\"0.2\",\n",
    "                            verbose=False):\n",
    "    uri = f'{wds_url}/{instance_id}/tsv/v{api_version}/{type_name}'\n",
    "    test_file = open(tsv_file_path, \"rb\")\n",
    "    \n",
    "    response = requests.post(uri, headers=HEADERS_GET, files = {\"records\": test_file})\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# cbas functions\n",
    "def create_method_with_github_link(cbas_url,\n",
    "                                   method_name,\n",
    "                                   github_url,\n",
    "                                   method_version,\n",
    "                                   method_source=\"GitHub\",\n",
    "                                   verbose=False):\n",
    "    \n",
    "    uri = f'{cbas_url}/api/batch/v1/methods'\n",
    "    post_body = json.dumps({\n",
    "        'method_name': method_name,\n",
    "        'method_source': method_source,\n",
    "        'method_version': method_version,\n",
    "        'method_url': github_url\n",
    "    })\n",
    "    \n",
    "    response = requests.post(uri, headers=HEADERS_POST, data=post_body)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def get_methods(cbas_url,\n",
    "                show_versions=True,\n",
    "                verbose=False):\n",
    "    \n",
    "    uri = f'{cbas_url}/api/batch/v1/methods?show_versions={show_versions}'\n",
    "    response = requests.get(uri, headers=HEADERS_GET)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def get_method_info(cbas_url,\n",
    "                    method_id,\n",
    "                    verbose=False):\n",
    "    \n",
    "    uri = f'{cbas_url}/api/batch/v1/methods?method_id={method_id}'\n",
    "    response = requests.get(uri, headers=HEADERS_GET)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def get_run_sets_for_method(cbas_url,\n",
    "                            method_id,\n",
    "                            page_size=1,\n",
    "                            verbose=False):\n",
    "    \n",
    "    uri = f'{cbas_url}/api/batch/v1/run_sets?method_id={method_id}&page_size=1'\n",
    "    response = requests.get(uri, headers=HEADERS_GET)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def submit_run_set(cbas_url,\n",
    "                   post_body,\n",
    "                   verbose=False):\n",
    "    \n",
    "    uri = f'{cbas_url}/api/batch/v1/run_sets'\n",
    "    \n",
    "    response = requests.post(uri, headers=HEADERS_POST, data=post_body)\n",
    "    status_code = response.status_code\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grab user/control workspace related information - needs to be filled out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control workspace ID:                  7a6ab368-c165-48ae-8b9a-a2cf1138ef1c\n",
      "control storage container resource ID: bd889533-6a32-4374-8dc4-74c9a697d6d5\n",
      "control cbas uri ID:                  https://lzf42bf0dc63c251179adc6ee67ef00d66ba53808001a58d33.servicebus.windows.net/terra-app-7e72dad7-3ec0-4ce9-a767-aeee668c1b45-7a6ab368-c165-48ae-8b9a-a2cf1138ef1c/cbas\n",
      "control wds uri:                      https://lzf42bf0dc63c251179adc6ee67ef00d66ba53808001a58d33.servicebus.windows.net/wds-7a6ab368-c165-48ae-8b9a-a2cf1138ef1c-7a6ab368-c165-48ae-8b9a-a2cf1138ef1c/\n",
      "user workspace ID:                  a5ec64f3-69e4-4646-8fb6-db4f882a2dd6\n",
      "user storage container resource ID: ebe08011-551d-4cd8-97eb-07970e90eade\n",
      "user wds uri:                      https://lz73d55620961cdabc5847f29f7780900840a75d86a8043662.servicebus.windows.net/wds-a5ec64f3-69e4-4646-8fb6-db4f882a2dd6-a5ec64f3-69e4-4646-8fb6-db4f882a2dd6/\n"
     ]
    }
   ],
   "source": [
    "# retrieve info for control workspace\n",
    "ctrl_ws_project= 'dsp-azure-general'\n",
    "ctrl_ws_name = 'js-imputation-pipeline-testingg'\n",
    "\n",
    "ctrl_ws_id = get_workspace_id(ctrl_ws_project, ctrl_ws_name)\n",
    "ctrl_ws_sc_id = get_workspace_sc_resource_id(ctrl_ws_id)\n",
    "\n",
    "print(f'control workspace ID:                  {ctrl_ws_id}')\n",
    "print(f'control storage container resource ID: {ctrl_ws_sc_id}')\n",
    "\n",
    "ctrl_cbas_uri = ''\n",
    "ctrl_wds_uri = ''\n",
    "get_apps_response = get_apps_for_workspace_id(ctrl_ws_id)\n",
    "for app in get_apps_response:\n",
    "    if app['appType'] == 'CROMWELL':\n",
    "       ctrl_cbas_uri = app['proxyUrls']['cbas']\n",
    "    if app['appType'] == 'WDS':\n",
    "       ctrl_wds_uri = app['proxyUrls']['wds']\n",
    "\n",
    "print(f'control cbas uri ID:                  {ctrl_cbas_uri}')\n",
    "print(f'control wds uri:                      {ctrl_wds_uri}')\n",
    "    \n",
    "# retrieve info for user workspace\n",
    "user_ws_project = 'azure-featured-workspaces'\n",
    "user_ws_name = 'Imputation User Workspace'\n",
    "\n",
    "user_ws_id = get_workspace_id(user_ws_project, user_ws_name)\n",
    "user_ws_sc_id = get_workspace_sc_resource_id(user_ws_id)\n",
    "\n",
    "print(f'user workspace ID:                  {user_ws_id}')\n",
    "print(f'user storage container resource ID: {user_ws_sc_id}')\n",
    "\n",
    "user_wds_uri = ''\n",
    "get_apps_response = get_apps_for_workspace_id(user_ws_id)\n",
    "for app in get_apps_response:\n",
    "    if app['appType'] == 'WDS':\n",
    "       user_wds_uri = app['proxyUrls']['wds']\n",
    "    \n",
    "print(f'user wds uri:                      {user_wds_uri}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write to Control WDS inputs \"passed in\" by user and copy to control workspace\n",
    "\n",
    "For this example we will just be copying one file from the user workspace to the control workspace and noting its path in WDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Scanning...\n",
      "INFO: Failed to create one or more destination container(s). Your transfers may still succeed if the container already exists.\n",
      "INFO: Any empty folders will not be processed, because source and/or destination doesn't have full folder support\n",
      "\n",
      "Job a9baddd6-25b1-2942-5321-964395eda833 has started\n",
      "Log file is located at: /home/jupyter/.azcopy/a9baddd6-25b1-2942-5321-964395eda833.log\n",
      "\n",
      "INFO: azcopy: A newer version 10.20.0 is available to download\n",
      "\n",
      "INFO: Could not read destination length. If the destination is write-only, use --check-length=false on the command line.\n",
      "100.0 %, 1 Done, 0 Failed, 0 Pending, 0 Skipped, 1 Total, \n",
      "\n",
      "\n",
      "Job a9baddd6-25b1-2942-5321-964395eda833 summary\n",
      "Elapsed Time (Minutes): 0.0333\n",
      "Number of File Transfers: 1\n",
      "Number of Folder Property Transfers: 0\n",
      "Total Number of Transfers: 1\n",
      "Number of Transfers Completed: 1\n",
      "Number of Transfers Failed: 0\n",
      "Number of Transfers Skipped: 0\n",
      "TotalBytesTransferred: 0\n",
      "Final Job Status: Completed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recordsModified': 1, 'message': 'Updated test_imputation_input'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you need to upload this file to the \"workspace files\" (storage container) of the user workspace\n",
    "user_file_to_copy = 'user_input_file.txt'  # change this as needed\n",
    "\n",
    "# path to where you want to copy the file in the control workspace, no need to change\n",
    "ctrl_file_destination = 'user_input_file_copy.txt'\n",
    "\n",
    "# get sas token for user file\n",
    "user_file_sas = get_sas_token_for_blob(user_file_to_copy, user_ws_id, user_ws_sc_id)\n",
    "\n",
    "# create a target destination SAS token\n",
    "# NOTE: according to documentation (https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-blobs-copy#guidelines)\n",
    "# if the copy is between tenants (which we do want to support), we can't use Azure Active Directory (Azure AD) authentication\n",
    "# and must instead use SAS tokens.\n",
    "ctrl_file_sas = get_sas_token_for_blob(ctrl_file_destination, \n",
    "                                       permissions='w',\n",
    "                                       ws_id=ctrl_ws_id,\n",
    "                                       ws_sc_id=ctrl_ws_sc_id)\n",
    "\n",
    "# azcopy needs the sas urls to be in quotes\n",
    "source_file_sas_with_quotes = f\"'{user_file_sas}'\"\n",
    "dest_file_sas_with_quotes = f\"'{ctrl_file_sas}'\"\n",
    "\n",
    "# do the copy\n",
    "!azcopy copy $source_file_sas_with_quotes $dest_file_sas_with_quotes\n",
    "\n",
    "# path to where you want to save wds tsv for the control workspace, no real need to change\n",
    "tsv_file_path = 'ctrl_wds.tsv'\n",
    "\n",
    "# data you want to add to control workspace wds, change as needed\n",
    "ctrl_file_uri = ctrl_file_sas.split(\"?\")[0] #TODO is there a way to get this uri from an api call directly?\n",
    "wds_table_name = \"test_imputation_input\"\n",
    "wds_table_headers = ['submission_id', 'input_file_location']\n",
    "wds_row_id = '123456'\n",
    "\n",
    "with open(tsv_file_path, 'w', newline='') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t', lineterminator='\\n')\n",
    "    writer.writerow(wds_table_headers)\n",
    "    writer.writerow([wds_row_id, ctrl_file_uri])\n",
    "    \n",
    "upload_records_for_type(ctrl_ws_id, wds_table_name, ctrl_wds_uri, tsv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create method from github link and run a workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method id: 4ad3bd70-486f-4d6a-be75-3f05af2881ce\n",
      "method version id: a1d09d99-332f-4046-b973-29e2db45b896\n",
      "{'run_set_name': 'what to do', 'run_set_description': 'any description you want from notebook', 'method_version_id': 'a1d09d99-332f-4046-b973-29e2db45b896', 'workflow_input_definitions': [{'input_name': 'HelloWorld.input_file', 'input_type': {'type': 'primitive', 'primitive_type': 'File'}, 'source': {'type': 'record_lookup', 'record_attribute': 'input_file_location'}}], 'workflow_output_definitions': [{'output_name': 'HelloWorld.output_file', 'output_type': {'type': 'primitive', 'primitive_type': 'File'}, 'destination': {'type': 'record_update', 'record_attribute': 'output_file'}}], 'wds_records': {'record_type': 'test_imputation_input', 'record_ids': ['123456']}}\n",
      "submission response: {'run_set_id': '253ec0dd-9834-4506-9ca7-05b904d617c6', 'runs': [{'run_id': 'df23e4f2-31a6-4dea-8abf-04be4caae8c9', 'state': 'UNKNOWN', 'errors': 'null'}], 'state': 'RUNNING'}\n"
     ]
    }
   ],
   "source": [
    "# create a cbas method given a github url\n",
    "method_name = 'tsps_notebook_hello_world_test_v1'\n",
    "github_url = ' https://github.com/broadinstitute/warp/blob/js_try_imputation_azure/pipelines/broad/arrays/imputation/hello_world.wdl'\n",
    "method_version = \"1.0\"\n",
    "\n",
    "create_method_with_github_link(ctrl_cbas_uri, method_name, github_url, method_version)\n",
    "\n",
    "# for the newly created method, get its method_id and method_version_id used for downstream functions\n",
    "method_id = \"\"\n",
    "method_version_id = \"\"\n",
    "get_methods_response = get_methods(ctrl_cbas_uri)\n",
    "for method in get_methods_response['methods']:\n",
    "    if method['name'] == method_name:\n",
    "        method_id = method['method_id']\n",
    "        method_version_id = method['method_versions'][0]['method_version_id']\n",
    "        \n",
    "print(f'method id: {method_id}')\n",
    "print(f'method version id: {method_version_id}')\n",
    "\n",
    "# in order to get the workflow_input_description and workflow_output_description that is used when generating a submission you can call the run_sets endpoint with your method id\n",
    "run_set_response = get_run_sets_for_method(ctrl_cbas_uri, method_id)\n",
    "run_set = run_set_response['run_sets'][0]\n",
    "workflow_input_definition = run_set['input_definition']\n",
    "workflow_output_definition = run_set['output_definition']\n",
    "\n",
    "# these can be very large so commenting them out by default\n",
    "\n",
    "#print(f'input definition: {workflow_input_definition}')\n",
    "#print(f'output definition: {workflow_output_definition}')\n",
    "\n",
    "\n",
    "# these values needed for a submission\n",
    "run_set_name = \"what to do\"\n",
    "run_set_description = \"any description you want from notebook\"\n",
    "\n",
    "# taking template and filling in the specific values for this hello world wdl.  you would want to generate this template using the workflow input/output definitions but as a PoC easier to just use one we already know about and fill in the unique values\n",
    "run_set_submission_post_template = {\"run_set_name\":\"\",\"run_set_description\":\"\",\"method_version_id\":\"\",\"workflow_input_definitions\":[{\"input_name\":\"HelloWorld.input_file\",\"input_type\":{\"type\":\"primitive\",\"primitive_type\":\"File\"},\"source\":{\"type\":\"record_lookup\",\"record_attribute\":\"input_file_location\"}}],\"workflow_output_definitions\":[{\"output_name\":\"HelloWorld.output_file\",\"output_type\":{\"type\":\"primitive\",\"primitive_type\":\"File\"},\"destination\":{\"type\":\"record_update\",\"record_attribute\":\"output_file\"}}],\"wds_records\":{\"record_type\":\"\",\"record_ids\":[]}}\n",
    "run_set_submission_post_template[\"run_set_name\"] = run_set_name\n",
    "run_set_submission_post_template[\"run_set_description\"] = run_set_description\n",
    "run_set_submission_post_template[\"method_version_id\"] = method_version_id\n",
    "run_set_submission_post_template[\"wds_records\"] = {\"record_type\":f\"{wds_table_name}\",\"record_ids\":[f\"{wds_row_id}\"]}\n",
    "\n",
    "# create your submission\n",
    "print(f'submission response: {submit_run_set(ctrl_cbas_uri, json.dumps(run_set_submission_post_template))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy outputs to user workspace and update user WDS with copied output location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Scanning...\n",
      "INFO: Failed to create one or more destination container(s). Your transfers may still succeed if the container already exists.\n",
      "INFO: Any empty folders will not be processed, because source and/or destination doesn't have full folder support\n",
      "\n",
      "Job fa5ebd5d-37c7-a846-697e-aa5c608713a3 has started\n",
      "Log file is located at: /home/jupyter/.azcopy/fa5ebd5d-37c7-a846-697e-aa5c608713a3.log\n",
      "\n",
      "INFO: azcopy: A newer version 10.20.0 is available to download\n",
      "\n",
      "INFO: Could not read destination length. If the destination is write-only, use --check-length=false on the command line.\n",
      "100.0 %, 1 Done, 0 Failed, 0 Pending, 0 Skipped, 1 Total, \n",
      "\n",
      "\n",
      "Job fa5ebd5d-37c7-a846-697e-aa5c608713a3 summary\n",
      "Elapsed Time (Minutes): 0.0335\n",
      "Number of File Transfers: 1\n",
      "Number of Folder Property Transfers: 0\n",
      "Total Number of Transfers: 1\n",
      "Number of Transfers Completed: 1\n",
      "Number of Transfers Failed: 0\n",
      "Number of Transfers Skipped: 0\n",
      "TotalBytesTransferred: 0\n",
      "Final Job Status: Completed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recordsModified': 1, 'message': 'Updated test_imputation_output'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you need to upload this file to the \"workspace files\" (storage container) of the control workspace\n",
    "ctrl_file_to_copy = 'ctrl_output_file.txt'  # change this as needed\n",
    "\n",
    "# where you want to copy this file in the users workspace, no need to change\n",
    "user_file_destination = 'blahblah/ctrl_output_file_copy.txt'\n",
    "\n",
    "# get sas token for user file\n",
    "ctrl_file_sas = get_sas_token_for_blob(ctrl_file_to_copy, ctrl_ws_id, ctrl_ws_sc_id)\n",
    "\n",
    "# create a target destination SAS token\n",
    "# NOTE: according to documentation (https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-blobs-copy#guidelines)\n",
    "# if the copy is between tenants (which we do want to support), we can't use Azure Active Directory (Azure AD) authentication\n",
    "# and must instead use SAS tokens.\n",
    "user_file_sas = get_sas_token_for_blob(user_file_destination, \n",
    "                                       permissions='w',\n",
    "                                       ws_id=user_ws_id,\n",
    "                                       ws_sc_id=user_ws_sc_id)\n",
    "\n",
    "# azcopy needs the sas urls to be in quotes\n",
    "source_file_sas_with_quotes = f\"'{ctrl_file_sas}'\"\n",
    "dest_file_sas_with_quotes = f\"'{user_file_sas}'\"\n",
    "\n",
    "# do the copy\n",
    "!azcopy copy $source_file_sas_with_quotes $dest_file_sas_with_quotes\n",
    "\n",
    "# add location of copied file to user WDS along with the \"unique identifier\"\n",
    "tsv_file_path = 'user_wds.tsv'\n",
    "ctrl_file_uri = user_file_sas.split(\"?\")[0]\n",
    "wds_table_name = \"test_imputation_output\"\n",
    "wds_table_headers = ['submission_id', 'output_file_location']\n",
    "\n",
    "with open(tsv_file_path, 'w', newline='') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t', lineterminator='\\n')\n",
    "    writer.writerow(wds_table_headers)\n",
    "    writer.writerow([wds_row_id, ctrl_file_uri])\n",
    "    \n",
    "upload_records_for_type(user_ws_id, wds_table_name, user_wds_uri, tsv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
